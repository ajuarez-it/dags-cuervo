name: Deploy Modified Airflow DAGs to GCS (PRD)

on:
  push:
    branches:
      - main
    pull_request:
      - main
    paths:
      - '**.py' # Optional: Only triggers the workflow if a .py file is changed

jobs:
  upload-dags:
    name: Deploy New DAGs to PRD
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    environment:
      name: prd
      url: 'http//dev.myapp.com'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS }}'

      - name: Get new Python files
        id: get_files
        run: |
          # Determine the correct commits to compare based on the event type
          if [ "${{ github.event_name }}" == "push" ]; then
            BASE_SHA="${{ github.event.before }}"
            HEAD_SHA="${{ github.sha }}"
          elif [ "${{ github.event_name }}" == "pull_request" ]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            HEAD_SHA="${{ github.event.pull_request.head.sha }}"
          fi

          echo "Finding new .py files between $BASE_SHA and $HEAD_SHA..."
          
          # Use --diff-filter=A to list only files that were Added.
          # The '|| true' prevents the step from failing if grep finds no matches.
          NEW_FILES=$(git diff --name-only --diff-filter=A "$BASE_SHA" "$HEAD_SHA" | grep '\.py$' || true)
          
          # This is the recommended way to pass multi-line strings between steps
          echo 'files<<EOF' >> "$GITHUB_OUTPUT"
          echo "$NEW_FILES" >> "$GITHUB_OUTPUT"
          echo 'EOF' >> "$GITHUB_OUTPUT"

      - name: Prepare and upload new files
        if: steps.get_files.outputs.files != ''
        run: |
          echo "New files to upload:"
          echo "${{ steps.get_files.outputs.files }}"
          
          mkdir staging_dir
          
          # Use a robust 'while read' loop to process each file path safely
          echo "${{ steps.get_files.outputs.files }}" | while IFS= read -r file; do
            if [ -n "$file" ]; then
              cp --parents "$file" staging_dir/
            fi
          done
          
          echo "Uploading new files to GCS..."
          gcloud storage cp --recursive staging_dir/* gs://us-central1-cc-data-analyti-d9b71af5-bucket/dags/